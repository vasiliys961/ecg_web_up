# -*- coding: utf-8 -*-
"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ CSV-—Ñ–∞–π–ª–∞ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–Ω—Å–∞–º–±–ª—å –∏–∑ MLP, 1D CNN –∏ ResNet1D –º–æ–¥–µ–ª–µ–π.
"""
# === –ò–º–ø–æ—Ä—Ç—ã ===
# –í–ê–ñ–ù–û: –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –¥–æ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è!
import os
import numpy as np
import pandas as pd
# --- –ò–ú–ü–û–†–¢ PYTORCH –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ó–î–ï–°–¨ ---
import torch
import torch.nn as nn
# ---------------------------------------

# === –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –º–æ–¥–µ–ª–µ–π –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ ===
# –≠—Ç–∏ –ø—É—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ ecg_web_app
# –û–Ω–∏ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –∏–∑ app.py, –Ω–æ –≤ analyze –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è model_dir

# === –°–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–≤–æ–¥–æ–≤ scp_codes –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ ===
DIAGNOSIS_TRANSLATION = {
    'SR': '–°–∏–Ω—É—Å–æ–≤—ã–π —Ä–∏—Ç–º',
    'NORM': '–ù–æ—Ä–º–∞–ª—å–Ω–∞—è –≠–ö–ì',
    'ABQRS': '–ê–±–µ—Ä—Ä–∞–Ω—Ç–Ω—ã–π QRS –∫–æ–º–ø–ª–µ–∫—Å',
    'IMI': '–ò–Ω—Ñ–∞—Ä–∫—Ç –º–∏–æ–∫–∞—Ä–¥–∞ (–Ω–∏–∂–Ω—è—è —Å—Ç–µ–Ω–∫–∞)',
    'ASMI': '–ò–Ω—Ñ–∞—Ä–∫—Ç –º–∏–æ–∫–∞—Ä–¥–∞ (–ø–µ—Ä–µ–¥–Ω–µ–ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ—á–Ω–∞—è —Å—Ç–µ–Ω–∫–∞)',
    'LVH': '–ì–∏–ø–µ—Ä—Ç—Ä–æ—Ñ–∏—è –ª–µ–≤–æ–≥–æ –∂–µ–ª—É–¥–æ—á–∫–∞',
    'NDT': '–ù–µ—Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è ST-T',
    'LAFB': '–ë–ª–æ–∫–∞–¥–∞ –ø–µ—Ä–µ–¥–Ω–µ–π –≤–µ—Ç–≤–∏ –ª–µ–≤–æ–π –Ω–æ–∂–∫–∏ –ø—É—á–∫–∞ –ì–∏—Å–∞',
    'AFIB': '–§–∏–±—Ä–∏–ª–ª—è—Ü–∏—è –ø—Ä–µ–¥—Å–µ—Ä–¥–∏–π',
    'PVC': '–ü—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∂–µ–ª—É–¥–æ—á–∫–æ–≤–æ–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ',
    'IRBBB': '–ù–µ–ø–æ–ª–Ω–∞—è –±–ª–æ–∫–∞–¥–∞ –ø—Ä–∞–≤–æ–π –Ω–æ–∂–∫–∏ –ø—É—á–∫–∞ –ì–∏—Å–∞',
    'VCLVH': '–ì–∏–ø–µ—Ä—Ç—Ä–æ—Ñ–∏—è –∂–µ–ª—É–¥–æ—á–∫–æ–≤ –∏–ª–∏ –ª–µ–≤–æ–≥–æ –∂–µ–ª—É–¥–æ—á–∫–∞',
    'STACH': '–°–∏–Ω—É—Å–æ–≤–∞—è —Ç–∞—Ö–∏–∫–∞—Ä–¥–∏—è',
    'IVCD': '–í–Ω—É—Ç—Ä–∏–∂–µ–ª—É–¥–æ—á–∫–æ–≤–∞—è –±–ª–æ–∫–∞–¥–∞',
    'SARRH': '–°–∏–Ω—É—Å–æ–≤—ã–π —Ä–∏—Ç–º —Å –∞–±–µ—Ä—Ä–∞–Ω—Ç–Ω—ã–º –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ–º',
    'ISCAL': '–ò—à–µ–º–∏—è –º–∏–æ–∫–∞—Ä–¥–∞ (–Ω–∏–∂–Ω—è—è —Å—Ç–µ–Ω–∫–∞)',
    'SBRAD': '–°–∏–Ω—É—Å–æ–≤–∞—è –±—Ä–∞–¥–∏–∫–∞—Ä–¥–∏—è',
    'QWAVE': '–ü–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π Q-–≤–æ–ª–Ω–æ–≤–æ–π –∫–æ–º–ø–ª–µ–∫—Å',
    'CRBBB': '–ü–æ–ª–Ω–∞—è –±–ª–æ–∫–∞–¥–∞ –ø—Ä–∞–≤–æ–π –Ω–æ–∂–∫–∏ –ø—É—á–∫–∞ –ì–∏—Å–∞',
    'CLBBB': '–ü–æ–ª–Ω–∞—è –±–ª–æ–∫–∞–¥–∞ –ª–µ–≤–æ–π –Ω–æ–∂–∫–∏ –ø—É—á–∫–∞ –ì–∏—Å–∞',
    'ILMI': '–ò–Ω—Ñ–∞—Ä–∫—Ç –º–∏–æ–∫–∞—Ä–¥–∞ (–Ω–∏–∂–Ω–µ–±–æ–∫–æ–≤–∞—è —Å—Ç–µ–Ω–∫–∞)',
    'LOWT': '–ù–∏–∑–∫–∏–π T-–≤–æ–ª–Ω–æ–≤–æ–π –∫–æ–º–ø–ª–µ–∫—Å',
    'PAC': '–ü—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–µ—Ä–¥–Ω–æ–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ',
    'AMI': '–û—Å—Ç—Ä—ã–π –∏–Ω—Ñ–∞—Ä–∫—Ç –º–∏–æ–∫–∞—Ä–¥–∞ (–ø–µ—Ä–µ–¥–Ω—è—è —Å—Ç–µ–Ω–∫–∞)',
}

# === –¢–æ–ø-24 –¥–∏–∞–≥–Ω–æ–∑–∞ (–≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ!) ===
TOP_24_CODES = ['SR', 'NORM', 'ABQRS', 'IMI', 'ASMI', 'LVH', 'NDT', 'LAFB', 'AFIB', 'PVC',
                'IRBBB', 'VCLVH', 'STACH', 'IVCD', 'SARRH', 'ISCAL', 'SBRAD', 'QWAVE',
                'CRBBB', 'CLBBB', 'ILMI', 'LOWT', 'PAC', 'AMI']

# === –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –º–æ–¥–µ–ª–µ–π ===

def create_mlp_model(input_dim, num_classes=24):
    """–°–æ–∑–¥–∞–µ—Ç MLP –º–æ–¥–µ–ª—å, —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏."""
    return nn.Sequential(
        nn.Linear(input_dim, 256),
        nn.ReLU(),
        nn.BatchNorm1d(256),
        nn.Dropout(0.5),
        nn.Linear(256, 128),
        nn.ReLU(),
        nn.BatchNorm1d(128),
        nn.Dropout(0.4),
        nn.Linear(128, 64),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(64, num_classes),
        # nn.Sigmoid() # –ù–µ –≤–∫–ª—é—á–∞–µ–º, —Ç–∞–∫ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º BCEWithLogitsLoss
    )

class ECG1DCNN(nn.Module):
    def __init__(self, num_classes=24, input_channels=1, input_length=531):
        super(ECG1DCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Dropout(0.2),
            nn.Conv1d(64, 128, kernel_size=5, padding=2),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Dropout(0.3),
            nn.Conv1d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(32) # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø—É–ª–∏–Ω–≥ –¥–ª—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        )
        self.classifier = nn.Sequential(
            nn.Linear(256 * 32, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1) # Flatten
        x = self.classifier(x)
        return x # BCEWithLogitsLoss

# --- ResNet1D (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è) ---
class ResidualBlock1d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, downsample=None):
        super(ResidualBlock1d, self).__init__()
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2, bias=False)
        self.bn1 = nn.BatchNorm1d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding=kernel_size//2, bias=False)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.downsample = downsample

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out

class ResNet1d(nn.Module):
    def __init__(self, block, layers, num_classes=24, input_channels=1, input_length=531):
        super(ResNet1d, self).__init__()
        self.in_channels = 64
        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm1d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º AdaptiveAvgPool1d –¥–ª—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã—Ö–æ–¥–∞
        self.avgpool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Linear(512, num_classes)

    def _make_layer(self, block, out_channels, blocks, stride=1):
        downsample = None
        if stride != 1 or self.in_channels != out_channels:
            downsample = nn.Sequential(
                nn.Conv1d(self.in_channels, out_channels, 1, stride, bias=False),
                nn.BatchNorm1d(out_channels),
            )
        layers = []
        layers.append(block(self.in_channels, out_channels, 3, stride, downsample))
        self.in_channels = out_channels
        for _ in range(1, blocks):
            layers.append(block(out_channels, out_channels))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x # BCEWithLogitsLoss

def resnet18_1d(**kwargs):
    model = ResNet1d(ResidualBlock1d, [2, 2, 2, 2], **kwargs)
    return model

# === –õ–æ–≥–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª—è ===

def load_ensemble_models(device, model_dir="models"):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–∏ –º–æ–¥–µ–ª–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å.
    Args:
        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π.
        model_dir (str): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—è–º–∏.
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.
    """
    models = {}
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏–∑: {model_dir}")
    
    # - –ó–∞–≥—Ä—É–∂–∞–µ–º MLP -
    mlp_path = os.path.join(model_dir, "ecg_model.pth")
    if os.path.exists(mlp_path):
        try:
            model_mlp = create_mlp_model(input_dim=531, num_classes=24).to(device)
            checkpoint_mlp = torch.load(mlp_path, map_location=device)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ 'state_dict' –≤ —á–µ–∫–ø–æ–∏–Ω—Ç–µ
            if 'state_dict' in checkpoint_mlp:
                state_dict_mlp = checkpoint_mlp['state_dict']
            elif 'model_state_dict' in checkpoint_mlp:
                state_dict_mlp = checkpoint_mlp['model_state_dict']
            else:
                state_dict_mlp = checkpoint_mlp # –ü—Ä—è–º–æ state_dict
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —É–±–∏—Ä–∞—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å 'net.'
            new_state_dict = {}
            for k, v in state_dict_mlp.items():
                if k.startswith('net.'):
                    new_key = k[4:] # –£–±–∏—Ä–∞–µ–º 'net.'
                    new_state_dict[new_key] = v
                else:
                    new_state_dict[k] = v
            model_mlp.load_state_dict(new_state_dict)
            model_mlp.eval()
            models["MLP"] = model_mlp
            print("‚úÖ MLP –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MLP: {e}")
    else:
        print(f"‚ùå –§–∞–π–ª MLP –Ω–µ –Ω–∞–π–¥–µ–Ω: {mlp_path}")

    # - –ó–∞–≥—Ä—É–∂–∞–µ–º 1D CNN -
    cnn_path = os.path.join(model_dir, "ecg_1dcnn_best.pth")
    if os.path.exists(cnn_path):
        try:
            model_cnn = ECG1DCNN(num_classes=24, input_channels=1, input_length=531).to(device)
            checkpoint_cnn = torch.load(cnn_path, map_location=device)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ 'state_dict' –≤ —á–µ–∫–ø–æ–∏–Ω—Ç–µ
            if 'state_dict' in checkpoint_cnn:
                state_dict_cnn = checkpoint_cnn['state_dict']
            elif 'model_state_dict' in checkpoint_cnn:
                state_dict_cnn = checkpoint_cnn['model_state_dict']
            else:
                state_dict_cnn = checkpoint_cnn # –ü—Ä—è–º–æ state_dict
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —É–±–∏—Ä–∞—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å 'net.'
            new_state_dict_cnn = {}
            for k, v in state_dict_cnn.items():
                if k.startswith('net.'):
                    new_key = k[4:] # –£–±–∏—Ä–∞–µ–º 'net.'
                    new_state_dict_cnn[new_key] = v
                else:
                    new_state_dict_cnn[k] = v
            model_cnn.load_state_dict(new_state_dict_cnn)
            model_cnn.eval()
            models["CNN"] = model_cnn
            print("‚úÖ 1D CNN –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ 1D CNN: {e}")
    else:
        print(f"‚ùå –§–∞–π–ª 1D CNN –Ω–µ –Ω–∞–π–¥–µ–Ω: {cnn_path}")

    # - –ó–∞–≥—Ä—É–∂–∞–µ–º ResNet1D -
    resnet_path = os.path.join(model_dir, "ecg_resnet1d_features_best.pth")
    if os.path.exists(resnet_path):
        try:
            model_resnet = resnet18_1d(num_classes=24, input_channels=1, input_length=531).to(device)
            checkpoint_resnet = torch.load(resnet_path, map_location=device)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ 'state_dict' –≤ —á–µ–∫–ø–æ–∏–Ω—Ç–µ
            if 'state_dict' in checkpoint_resnet:
                state_dict_resnet = checkpoint_resnet['state_dict']
            elif 'model_state_dict' in checkpoint_resnet:
                state_dict_resnet = checkpoint_resnet['model_state_dict']
            else:
                state_dict_resnet = checkpoint_resnet # –ü—Ä—è–º–æ state_dict
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —É–±–∏—Ä–∞—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å 'net.'
            new_state_dict_resnet = {}
            for k, v in state_dict_resnet.items():
                if k.startswith('net.'):
                    new_key = k[4:] # –£–±–∏—Ä–∞–µ–º 'net.'
                    new_state_dict_resnet[new_key] = v
                else:
                    new_state_dict_resnet[k] = v
            model_resnet.load_state_dict(new_state_dict_resnet)
            model_resnet.eval()
            models["ResNet"] = model_resnet
            print("‚úÖ ResNet1D –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ResNet1D: {e}")
    else:
        print(f"‚ùå –§–∞–π–ª ResNet1D –Ω–µ –Ω–∞–π–¥–µ–Ω: {resnet_path}")

    if not models:
        raise RuntimeError("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è.")
    return models

def get_ensemble_predictions(X_dense, X_1d, models_dict, device):
    """–î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–º.
    Args:
        X_dense (np.ndarray): –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è MLP, —Ñ–æ—Ä–º–∞ (N, 531).
        X_1d (np.ndarray): –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è CNN/ResNet, —Ñ–æ—Ä–º–∞ (N, 1, 531).
        models_dict (dict): –°–ª–æ–≤–∞—Ä—å —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.
        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.
    Returns:
        np.ndarray: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, —Ñ–æ—Ä–º–∞ (N, 24).
    """
    all_preds = []
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ torch.Tensor –∏ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    X_dense_torch = torch.tensor(X_dense, dtype=torch.float32).to(device)
    X_1d_torch = torch.tensor(X_1d, dtype=torch.float32).to(device)
    
    with torch.no_grad():
        # - MLP -
        if "MLP" in models_dict:
            model_mlp = models_dict["MLP"]
            logits_mlp = model_mlp(X_dense_torch)
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–∏–≥–º–æ–∏–¥—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            probs_mlp = torch.sigmoid(logits_mlp)
            # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ CPU –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
            all_preds.append(probs_mlp.cpu().numpy())
        
        # - 1D CNN -
        if "CNN" in models_dict:
            model_cnn = models_dict["CNN"]
            logits_cnn = model_cnn(X_1d_torch)
            probs_cnn = torch.sigmoid(logits_cnn)
            all_preds.append(probs_cnn.cpu().numpy())
        
        # - ResNet1D -
        if "ResNet" in models_dict:
            model_resnet = models_dict["ResNet"]
            logits_resnet = model_resnet(X_1d_torch)
            probs_resnet = torch.sigmoid(logits_resnet)
            all_preds.append(probs_resnet.cpu().numpy())
    
    if not all_preds:
        raise RuntimeError("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∏ –æ—Ç –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏.")
    
    # - –£—Å—Ä–µ–¥–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è -
    # all_preds - —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –º–∞—Å—Å–∏–≤–æ–≤ numpy, –∫–∞–∂–¥—ã–π —Ä–∞–∑–º–µ—Ä–æ–º (N, 24)
    # np.mean –ø–æ –æ—Å–∏ 0 —É—Å—Ä–µ–¥–Ω–∏—Ç –ø–æ –º–æ–¥–µ–ª—è–º
    ensemble_proba = np.mean(np.array(all_preds), axis=0)
    return ensemble_proba

# === –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ ===
def analyze(csv_file_path, model_dir="models"):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç CSV-—Ñ–∞–π–ª —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–∏–∞–≥–Ω–æ–∑–æ–≤ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏.
    Args:
        csv_file_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É CSV.
        model_dir (str): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—è–º–∏ –∏ —Ñ–∞–π–ª–∞–º–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.
    Returns:
        list[dict]: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–∞–º–∏ 'code', 'ru_name', 'probability'.
    Raises:
        FileNotFoundError: –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –∏–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.
        ValueError: –ï—Å–ª–∏ —Ñ–∞–π–ª CSV –∏–º–µ–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.
        RuntimeError: –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–ª–∏ –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
    """
    print(f"–ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ CSV —Ñ–∞–π–ª–∞: {csv_file_path}")
    print(f"–ü–∞–ø–∫–∞ –º–æ–¥–µ–ª–µ–π: {model_dir}")

    # --- –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ---
    # –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å MPS
    device = torch.device("cpu")
    print("‚ö†Ô∏è –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU.")
    # ------------------------------------------------------------------------------
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    # --- –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ ---
    mean_path = os.path.join(model_dir, "ecg_train_mean.npy")
    std_path = os.path.join(model_dir, "ecg_train_std.npy")
    if not os.path.exists(mean_path) or not os.path.exists(std_path):
        raise FileNotFoundError(f"–§–∞–π–ª—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {mean_path}, {std_path}")
    train_mean = np.load(mean_path)
    train_std = np.load(std_path)
    print(f"‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. Mean shape: {train_mean.shape}, Std shape: {train_std.shape}")

    # --- –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ ---
    try:
        df_new = pd.read_csv(csv_file_path)
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. Shape: {df_new.shape}")
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {csv_file_path}: {e}")

    # --- –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ ---
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        feature_columns = [col for col in df_new.columns if col != 'ecg_id']
        if len(feature_columns) != 531:
            raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è 531 –ø—Ä–∏–∑–Ω–∞–∫, –Ω–æ –Ω–∞–π–¥–µ–Ω–æ {len(feature_columns)}. –ü—Ä–æ–≤–µ—Ä—å —Ñ–∞–π–ª {csv_file_path}.")
        X_new = df_new[feature_columns].values
        print(f"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã. Shape: {X_new.shape}")

        # --- –î–æ–±–∞–≤–ª–µ–Ω–æ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ NaN/Inf –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---
        if np.isnan(X_new).any() or np.isinf(X_new).any():
            print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –∏–ª–∏ Inf!")
            # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –∏ Inf –ø–µ—Ä–µ–¥ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
            # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
            nan_mask = np.isnan(X_new)
            if np.any(nan_mask):
                print("  -> –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ train_mean.")
                X_new = np.where(nan_mask, train_mean, X_new)
            
            # –ó–∞–º–µ–Ω—è–µ–º Inf –Ω–∞ –±–æ–ª—å—à–∏–µ –∫–æ–Ω–µ—á–Ω—ã–µ —á–∏—Å–ª–∞
            X_new = np.nan_to_num(X_new, nan=0.0, posinf=1e6, neginf=-1e6)
            print("  -> –ó–∞–º–µ–Ω–µ–Ω—ã Inf –Ω–∞ –∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.")
            
        print(f"DEBUG (–∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ): Min: {np.min(X_new)}, Max: {np.max(X_new)}, Mean: {np.mean(X_new)}")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –æ–±—É—á–µ–Ω–∏—è!)
        # np.where(std == 0, 1.0, std) —É–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
        X_new = (X_new - train_mean) / train_std
        print("‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã.")

        # --- –î–æ–±–∞–≤–ª–µ–Ω–æ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ ---
        if np.isnan(X_new).any() or np.isinf(X_new).any():
            print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –∏–ª–∏ Inf –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏!")
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –∏—Ö
            X_new = np.nan_to_num(X_new, nan=0.0, posinf=1e6, neginf=-1e6)
            print("  -> –ó–∞–º–µ–Ω–µ–Ω—ã NaN/Inf –Ω–∞ –∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.")

        print(f"DEBUG (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ): Min: {np.min(X_new)}, Max: {np.max(X_new)}, Mean: {np.mean(X_new)}")

        # –î–ª—è 1D –º–æ–¥–µ–ª–µ–π –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–∞–Ω–∞–ª–∞
        X_new_1d = X_new[:, np.newaxis, :]  # –§–æ—Ä–º–∞—Ç: (N, 1, 531)
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–ª—è 1D –º–æ–¥–µ–ª–µ–π. Shape: {X_new_1d.shape}")

        # –î–∞–Ω–Ω—ã–µ –¥–ª—è MLP (–±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏)
        X_new_dense = X_new  # –§–æ—Ä–º–∞—Ç: (N, 531)
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–ª—è MLP. Shape: {X_new_dense.shape}")

    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª—è ---
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
    try:
        models_dict = load_ensemble_models(device, model_dir)
        if not models_dict:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å –∞–Ω—Å–∞–º–±–ª—è.")
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –º–æ–¥–µ–ª–∏: {list(models_dict.keys())}")
    except Exception as e:
        raise RuntimeError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")

    # --- –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è ---
    print("üîÆ –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è...")
    try:
        predictions_proba = get_ensemble_predictions(X_new_dense, X_new_1d, models_dict, device)
        if predictions_proba.size == 0:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.")
        print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—É—á–µ–Ω—ã. Shape: {predictions_proba.shape}")

        # --- –î–æ–±–∞–≤–ª–µ–Ω–æ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö ---
        if np.isnan(predictions_proba).any():
            print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN!")
        if np.isinf(predictions_proba).any():
            print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã Inf!")
        print(f"DEBUG (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è): Min: {np.min(predictions_proba)}, Max: {np.max(predictions_proba)}, Mean: {np.mean(predictions_proba)}")
        print(f"DEBUG (–ø–µ—Ä–≤—ã–µ 5 –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è 1-–π –≠–ö–ì): {predictions_proba[0][:5]}")

    except Exception as e:
        raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {e}")

    # --- –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ---
    results = []
    # –ë–µ—Ä–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –≠–ö–ì –≤ —Ñ–∞–π–ª–µ (–∏–ª–∏ –¥–ª—è –≤—Å–µ—Ö, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    # –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –≠–ö–ì –∏–∑ —Ñ–∞–π–ª–∞
    if predictions_proba.shape[0] > 0:
        probs = predictions_proba[0]
        print(f"DEBUG: –ü–µ—Ä–≤—ã–µ 3 –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –º–æ–¥–µ–ª–∏ (–¥–ª—è 1-–π –≠–ö–ì): {probs[:3]}")
        for i, code in enumerate(TOP_24_CODES):
            ru_name = DIAGNOSIS_TRANSLATION.get(code, code)
            prob = probs[i]
            print(f"DEBUG: –î–∏–∞–≥–Ω–æ–∑ {code}, –∏–Ω–¥–µ–∫—Å {i}, –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∏–∑ probs[i]: {prob}, —Ç–∏–ø: {type(prob)}")
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–æ–ø—É—Å—Ç–∏–º–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º
            if not (np.isnan(prob) or np.isinf(prob)):
                results.append({
                    'code': code,
                    'ru_name': ru_name,
                    'probability': float(prob) # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ç–∏–ø Python
                })
            else:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –¥–∏–∞–≥–Ω–æ–∑ {code} –∏–∑-–∑–∞ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: {prob}")
                # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.0, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –¥–∏–∞–≥–Ω–æ–∑—ã
                # results.append({'code': code, 'ru_name': ru_name, 'probability': 0.0})

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        results.sort(key=lambda x: x['probability'], reverse=True)
        print(f"‚úÖ –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ù–∞–π–¥–µ–Ω–æ {len(results)} –¥–∏–∞–≥–Ω–æ–∑–æ–≤.")
    else:
        print("‚ö†Ô∏è –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø—É—Å—Ç—ã, —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—É–¥–µ—Ç –ø—É—Å—Ç.")

    # –í–ê–ñ–ù–û: –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ results
    if results:
        print(f"DEBUG: –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç results –ø–µ—Ä–µ–¥ return: {results[0]}")
    else:
        print("DEBUG: results –ø—É—Å—Ç –ø–µ—Ä–µ–¥ return.")

    print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ CSV –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(results)} –¥–∏–∞–≥–Ω–æ–∑–æ–≤.")
    # --- –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–´–ô –í–û–ó–í–†–ê–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–ê ---
    return results
    # ------------------------------------------

